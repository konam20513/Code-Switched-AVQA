{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Reading file***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"merged_data_10000_ours.json\"\n",
    "\n",
    "data = []\n",
    "with open(json_file, 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "train_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>type</th>\n",
       "      <th>question_content</th>\n",
       "      <th>templ_values</th>\n",
       "      <th>question_deleted</th>\n",
       "      <th>anser</th>\n",
       "      <th>question</th>\n",
       "      <th>Quest_hindi</th>\n",
       "      <th>ans_hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000136</td>\n",
       "      <td>17</td>\n",
       "      <td>[\"Audio-Visual\", \"Comparative\"]</td>\n",
       "      <td>Is the instrument on the &lt;LR&gt; louder than the ...</td>\n",
       "      <td>[\"left\", \"right\"]</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>Is the instrument on the left louder than the ...</td>\n",
       "      <td>क्या बायीं ओर का वाद्ययंत्र दाहिनी ओर के वाद्य...</td>\n",
       "      <td>नहीं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000250</td>\n",
       "      <td>23</td>\n",
       "      <td>[\"Audio-Visual\", \"Existential\"]</td>\n",
       "      <td>Is the &lt;Object&gt; in the video always playing?</td>\n",
       "      <td>[\"accordion\"]</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Is the accordion in the video always playing?</td>\n",
       "      <td>क्या वीडियो में अकॉर्डियन हमेशा बजता रहता है?</td>\n",
       "      <td>हाँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000225</td>\n",
       "      <td>27</td>\n",
       "      <td>[\"Audio-Visual\", \"Existential\"]</td>\n",
       "      <td>Is there a voiceover?</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Is there a voiceover?</td>\n",
       "      <td>क्या कोई वॉयसओवर है?</td>\n",
       "      <td>हाँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000152</td>\n",
       "      <td>30</td>\n",
       "      <td>[\"Audio-Visual\", \"Existential\"]</td>\n",
       "      <td>Is this sound from the instrument in the video?</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Is this sound from the instrument in the video?</td>\n",
       "      <td>क्या यह ध्वनि वीडियो में मौजूद उपकरण की है?</td>\n",
       "      <td>हाँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000085</td>\n",
       "      <td>32</td>\n",
       "      <td>[\"Audio-Visual\", \"Existential\"]</td>\n",
       "      <td>Is there a voiceover?</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>Is there a voiceover?</td>\n",
       "      <td>क्या कोई वॉयसओवर है?</td>\n",
       "      <td>नहीं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>00003985</td>\n",
       "      <td>28445</td>\n",
       "      <td>[\"Visual\", \"Counting\"]</td>\n",
       "      <td>Are there &lt;Object&gt; and &lt;Object&gt; instruments in...</td>\n",
       "      <td>[\"banjo\", \"violin\"]</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Are there banjo and violin instruments in the ...</td>\n",
       "      <td>क्या वीडियो में बैंजो और वायलिन वाद्ययंत्र हैं?</td>\n",
       "      <td>हाँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>00000326</td>\n",
       "      <td>28446</td>\n",
       "      <td>[\"Audio\", \"Comparative\"]</td>\n",
       "      <td>Is the &lt;Object&gt; playing longer than the &lt;Object&gt;?</td>\n",
       "      <td>[\"piano\", \"violin\"]</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>Is the piano playing longer than the violin?</td>\n",
       "      <td>क्या पियानो वायलिन से अधिक देर तक बजता है?</td>\n",
       "      <td>नहीं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>00003730</td>\n",
       "      <td>28458</td>\n",
       "      <td>[\"Audio-Visual\", \"Comparative\"]</td>\n",
       "      <td>Is the &lt;Object&gt; on the &lt;LR&gt; more rhythmic than...</td>\n",
       "      <td>[\"cello\", \"left\", \"ukulele\", \"right\"]</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>Is the cello on the left more rhythmic than th...</td>\n",
       "      <td>क्या बायीं ओर का सेलो दायीं ओर के युकुलेले की ...</td>\n",
       "      <td>नहीं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>00008427</td>\n",
       "      <td>28462</td>\n",
       "      <td>[\"Visual\", \"Counting\"]</td>\n",
       "      <td>Are there &lt;Object&gt; and &lt;Object&gt; instruments in...</td>\n",
       "      <td>[\"violin\", \"cello\"]</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Are there violin and cello instruments in the ...</td>\n",
       "      <td>क्या वीडियो में वायलिन और सेलो वाद्ययंत्र हैं?</td>\n",
       "      <td>हाँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>vv00002309</td>\n",
       "      <td>28463</td>\n",
       "      <td>[\"Visual\", \"Counting\"]</td>\n",
       "      <td>Are there &lt;Object&gt; and &lt;Object&gt; instruments in...</td>\n",
       "      <td>[\"accordion\", \"xylophone\"]</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Are there accordion and xylophone instruments ...</td>\n",
       "      <td>क्या वीडियो में अकॉर्डियन और जाइलोफोन वाद्ययंत...</td>\n",
       "      <td>हाँ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id  question_id                             type  \\\n",
       "0       00000136           17  [\"Audio-Visual\", \"Comparative\"]   \n",
       "1       00000250           23  [\"Audio-Visual\", \"Existential\"]   \n",
       "2       00000225           27  [\"Audio-Visual\", \"Existential\"]   \n",
       "3       00000152           30  [\"Audio-Visual\", \"Existential\"]   \n",
       "4       00000085           32  [\"Audio-Visual\", \"Existential\"]   \n",
       "...          ...          ...                              ...   \n",
       "9995    00003985        28445           [\"Visual\", \"Counting\"]   \n",
       "9996    00000326        28446         [\"Audio\", \"Comparative\"]   \n",
       "9997    00003730        28458  [\"Audio-Visual\", \"Comparative\"]   \n",
       "9998    00008427        28462           [\"Visual\", \"Counting\"]   \n",
       "9999  vv00002309        28463           [\"Visual\", \"Counting\"]   \n",
       "\n",
       "                                       question_content  \\\n",
       "0     Is the instrument on the <LR> louder than the ...   \n",
       "1          Is the <Object> in the video always playing?   \n",
       "2                                 Is there a voiceover?   \n",
       "3       Is this sound from the instrument in the video?   \n",
       "4                                 Is there a voiceover?   \n",
       "...                                                 ...   \n",
       "9995  Are there <Object> and <Object> instruments in...   \n",
       "9996  Is the <Object> playing longer than the <Object>?   \n",
       "9997  Is the <Object> on the <LR> more rhythmic than...   \n",
       "9998  Are there <Object> and <Object> instruments in...   \n",
       "9999  Are there <Object> and <Object> instruments in...   \n",
       "\n",
       "                               templ_values  question_deleted anser  \\\n",
       "0                         [\"left\", \"right\"]                 0    no   \n",
       "1                             [\"accordion\"]                 0   yes   \n",
       "2                                        []                 0   yes   \n",
       "3                                        []                 0   yes   \n",
       "4                                        []                 0    no   \n",
       "...                                     ...               ...   ...   \n",
       "9995                    [\"banjo\", \"violin\"]                 0   yes   \n",
       "9996                    [\"piano\", \"violin\"]                 0    no   \n",
       "9997  [\"cello\", \"left\", \"ukulele\", \"right\"]                 0    no   \n",
       "9998                    [\"violin\", \"cello\"]                 0   yes   \n",
       "9999             [\"accordion\", \"xylophone\"]                 0   yes   \n",
       "\n",
       "                                               question  \\\n",
       "0     Is the instrument on the left louder than the ...   \n",
       "1         Is the accordion in the video always playing?   \n",
       "2                                 Is there a voiceover?   \n",
       "3       Is this sound from the instrument in the video?   \n",
       "4                                 Is there a voiceover?   \n",
       "...                                                 ...   \n",
       "9995  Are there banjo and violin instruments in the ...   \n",
       "9996       Is the piano playing longer than the violin?   \n",
       "9997  Is the cello on the left more rhythmic than th...   \n",
       "9998  Are there violin and cello instruments in the ...   \n",
       "9999  Are there accordion and xylophone instruments ...   \n",
       "\n",
       "                                            Quest_hindi ans_hindi  \n",
       "0     क्या बायीं ओर का वाद्ययंत्र दाहिनी ओर के वाद्य...      नहीं  \n",
       "1         क्या वीडियो में अकॉर्डियन हमेशा बजता रहता है?       हाँ  \n",
       "2                                  क्या कोई वॉयसओवर है?       हाँ  \n",
       "3           क्या यह ध्वनि वीडियो में मौजूद उपकरण की है?       हाँ  \n",
       "4                                  क्या कोई वॉयसओवर है?      नहीं  \n",
       "...                                                 ...       ...  \n",
       "9995    क्या वीडियो में बैंजो और वायलिन वाद्ययंत्र हैं?       हाँ  \n",
       "9996         क्या पियानो वायलिन से अधिक देर तक बजता है?      नहीं  \n",
       "9997  क्या बायीं ओर का सेलो दायीं ओर के युकुलेले की ...      नहीं  \n",
       "9998     क्या वीडियो में वायलिन और सेलो वाद्ययंत्र हैं?       हाँ  \n",
       "9999  क्या वीडियो में अकॉर्डियन और जाइलोफोन वाद्ययंत...       हाँ  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***English2Hingish***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Hinglish translation pipeline\n",
    "model_name = \"SkAndMl/english-to-hinglish\"\n",
    "pipe = pipeline(\"text2text-generation\", model=model_name)\n",
    "\n",
    "# Function to translate English to Hinglish\n",
    "def translate_to_hinglish(text):\n",
    "    return pipe(text)[0]['generated_text']\n",
    "\n",
    "train_df['hinglish_question'] = train_df['question'].apply(translate_to_hinglish)\n",
    "\n",
    "print(train_df[['question', 'hinglish_question']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hinglish embeddings***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_pooling_embedding(text):\n",
    "    # Tokenize input text\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    # Get model output\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    # Extract embeddings\n",
    "    embeddings = model_output.last_hidden_state\n",
    "    # Perform average pooling across the sequence dimension\n",
    "    input_mask_expanded = encoded_input['attention_mask'].unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = input_mask_expanded.sum(1)\n",
    "    sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "    mean_embeddings = sum_embeddings / sum_mask\n",
    "    return mean_embeddings\n",
    "\n",
    "# Assuming train_df['hinglish_question'] exists and contains the text entries\n",
    "embeddings_list = []\n",
    "\n",
    "for text in train_df['hinglish_question']:\n",
    "    embedding = get_average_pooling_embedding(text).cpu().numpy()  # Convert to NumPy array and ensure moving to CPU if necessary\n",
    "    embeddings_list.append(embedding.squeeze())  # Remove the singleton dimension\n",
    "\n",
    "# Convert the list of embeddings to a numpy array\n",
    "embeddings_array = np.vstack(embeddings_list)  # This will create a 2D array\n",
    "\n",
    "# Save the numpy array to a .npy file\n",
    "np.save('hingligh_question_embeddings.npy', embeddings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_json('merged_data_with_hinglish.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***English Embeddings***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_pooling_embedding(text):\n",
    "    # Tokenize input text\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    # Get model output\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    # Extract embeddings\n",
    "    embeddings = model_output.last_hidden_state\n",
    "    # Perform average pooling across the sequence dimension\n",
    "    input_mask_expanded = encoded_input['attention_mask'].unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = input_mask_expanded.sum(1)\n",
    "    sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "    mean_embeddings = sum_embeddings / sum_mask\n",
    "    return mean_embeddings\n",
    "\n",
    "# Assuming train_df['hinglish_question'] exists and contains the text entries\n",
    "embeddings_list = []\n",
    "\n",
    "for text in train_df['question']:\n",
    "    embedding = get_average_pooling_embedding(text).cpu().numpy()  # Convert to NumPy array and ensure moving to CPU if necessary\n",
    "    embeddings_list.append(embedding.squeeze())  # Remove the singleton dimension\n",
    "\n",
    "# Convert the list of embeddings to a numpy array\n",
    "embeddings_array = np.vstack(embeddings_list)  # This will create a 2D array\n",
    "\n",
    "# Save the numpy array to a .npy file\n",
    "np.save('english_question_embeddings.npy', embeddings_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hindi Embeddigs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_pooling_embedding(text):\n",
    "    # Tokenize input text\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    # Get model output\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    # Extract embeddings\n",
    "    embeddings = model_output.last_hidden_state\n",
    "    # Perform average pooling across the sequence dimension\n",
    "    input_mask_expanded = encoded_input['attention_mask'].unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = input_mask_expanded.sum(1)\n",
    "    sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "    mean_embeddings = sum_embeddings / sum_mask\n",
    "    return mean_embeddings\n",
    "\n",
    "# Assuming train_df['hinglish_question'] exists and contains the text entries\n",
    "embeddings_list = []\n",
    "\n",
    "for text in train_df['Quest_hindi']:\n",
    "    embedding = get_average_pooling_embedding(text).cpu().numpy()  # Convert to NumPy array and ensure moving to CPU if necessary\n",
    "    embeddings_list.append(embedding.squeeze())  # Remove the singleton dimension\n",
    "\n",
    "# Convert the list of embeddings to a numpy array\n",
    "embeddings_array = np.vstack(embeddings_list)  # This will create a 2D array\n",
    "\n",
    "# Save the numpy array to a .npy file\n",
    "np.save('hindi_question_embeddings.npy', embeddings_array)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
